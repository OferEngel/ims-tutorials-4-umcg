---
title: 'Readiness Assurance Week 9'
output:
  html_document:
    theme: cerulean
    highlight: pygments
    css: ../lab.css
    toc: true
    toc_float: true
---

```{r global_options, include=FALSE}
library(emo)
library(tidyverse)
library(broom)
library(infer)
library(santoku)
library(car)
library(GGally)
library(modelsummary)
library(easystats)
library(table1)
library(gt)
library(datawizard)
library(marginaleffects)

knitr::opts_chunk$set(echo = FALSE, 
                      fig.align = "center", 
                      # fig.height = 3, 
                      # fig.width = 5,
                      warning = FALSE, 
                      message = FALSE, 
                      eval = FALSE)




```



<span style="color: red;font-size: 14px;font-weight: bold;">
<br/>Please submit your answers to this RA [using this form](https://bit.ly/3MSy4wi). </span>


## Comparing groups

1. Treated with In Vitro Fertilisation (IVF), women between 30 and 35 years old have a probability of success (becoming pregnant) of 0.4. Ten women between 30 and 35, all independent of each other, will be in the IVF program next year. What is the probability that exactly 4 of them will become pregnant? [3]

```{r ex1-solution}
# dbinom(4, 10, 0.4) = 0.2508227
```


:::{#boxedtext}




This is an example for a question about the binomial distribution. Where we have a $N$ [bernoulli trials](https://en.wikipedia.org/wiki/Bernoulli_trial), each trial can end in a `success` or `failure`, and each trial has the same probability of `success`: $p$. 

The probability that **exactly** $n$ successes out of $N$ trials can be calculated in R using the following command: 

```{r ex-01, echo=TRUE, eval=FALSE}
dbinom(n, N, p)

```

So for example, if 50 women are giving birth, and we consider giving birth to a baby girl is a success with probability $p=0.49$, the probability of exactly 25 baby girls out of 50 births is `dbinom(25, 50, .49)`. 

The probability of 25 or more baby girls would be the sum


```{r ex-02, echo=TRUE, eval=FALSE}
dbinom(25, 50, 0.49) + 
  dbinom(26, 50, 0.49) +
  dbinom(27, 50, 0.49) + 
  ... + 
  dbinom(49, 50, 0.49) + 
  dbinom(50, 50, 0.49) 

```


It could also be calculated as `dbinom(25:50, 50, 0.49) |> sum()`.

:::

2.	For 36 – 40 years old women, following this IVF program, the probability to become pregnant equals 0.3. Two women from this group, and one woman aged 32 are in the IVF program, all independent of each other. What is the probability that exactly two of these three women will become pregnant? [6]

```{r}
# dbinom(2, 2, .3)*dbinom(0, 1, .4) + 
#   dbinom(1, 2, .3)*dbinom(1, 1, .4) = 0.222 or about 2/9
```


:::{#boxedtext}

In this question we have two pregnant women from the older group and one from the younger group. Your job is to calculate the probability that out of these three women, two will become pregnant. Two women will be pregnant in one of two ways:  

-   Either both women from the older group both get pregnant (but the younger will not), **OR**
-   One of the women from the older group will get pregnant AND the younger will get pregnant too. 

To answer this question, you need to add up two probabilities: 

-   The probability that the two women from the older group becomes pregnant (two successes in two trials) multiplied by the probability that the younger woman does NOT get pregnant (zero successes from one trial) `dbinom(__, 2, .3)*dbinom(__, 1, .4)`
-   The probability that the ONE woman from the older group becomes pregnant (one success in two trials)  multiplied by the probability that the younger woman gets pregnant (one success from one trial) `dbinom(__, 2, .3)*dbinom(__, 1, .4)`
 
You will need to add up the two probabilities, and that is your final answer! 
 
:::



3.	 [Ophthalmologists](https://en.wikipedia.org/wiki/Ophthalmology) want to compare two types of eye drops, A and B, to prevent dryness of the eye. 44 volunteers with dryness problems in both eyes receive A in the one eye and B in the other. They evaluate both eye drops with a binary response ("helpful" or "not helpful"). Perform a valid statistical test to test the null hypothesis that A and B have equal effects. Show your calculations and give your conclusion. [8]


```{r Ophthalmology, echo=FALSE, eval=TRUE}
library(gtExtras)

tribble(
  ~` `,   ~`Medicine B`,    ~freq, 
  "helpful",         "helpful",        18,
  "helpful",         "not helpful",    15,
  "not helpful",     "helpful",        5,
  "not helpful",     "not helpful",    6,
) |> pivot_wider(id_cols = ` `, 
                 names_from = `Medicine B`, 
                 values_from = freq, 
                 names_prefix = "Medicine B_") |> 
  mutate(
    outcome = "Medicine A", 
    sum = `Medicine B_helpful` + `Medicine B_not helpful`
    ) |> group_by(outcome) |> 
  gt( )  %>% 
  tab_spanner_delim(
    delim = "_"
  ) |> 
  summary_rows(
    # groups = everything(),
    columns = c(
      `Medicine B_helpful`, 
      `Medicine B_not helpful`, sum
      ),
    fns = list(
      total = "sum"
    )
  ) |> 
  gtExtras::gt_theme_espn()

```

:::{#boxedtext}
To answer this question you will use McNemar's test, which is effectively a chi-square test with one degree of freedom, where 

$$
\chi^2 = \frac{(b-c)^2}{(b+c)};~~~\text{df}=1
$$
To calculate the p-value associated with your $\chi^2$, simply use R as follows: 

```{r ex3-mcnemar, echo=TRUE}
pchisq(chi.sq, df = 1, lower.tail = FALSE)
```


:::

```{r ex3-solution}
pchisq((15 - 5)^2 / (15 + 5), df = 1, lower.tail = FALSE)
# 0.02534732
```


4.	Another group of ophthalmologists also want to compare eye drops A with eye drops B, but they have patients with dryness in one eye only. What kind of study design and statistical test would you advise this group to use? [4]


```{r ex-4}

# They could use a chi-square test
# One group n1 = 44 receive medicine A, 33 found it helpful and 11 unhelpful
# Second group n2 = 44 medicine B, 23 found it helpful and 21 unhelpful
M <- as.table(rbind(c(33, 11), c(23, 21)))
dimnames(M) <- list(
  medicine = c("A", "B"), 
  status = c("helpful", "unhelpful")
  )
chisq.test(M)

```


5.	In a certain population, systolic blood pressure (SBP) is normally distributed with a mean of 115 mm Hg and a standard deviation equal to 15 mm Hg. A random sample of 25 individuals was taken from this population. What is the probability that the mean SBP of this group will be smaller than 109 mm HG? [4]

:::{#boxedtext}

If we know that a variable has a normal distribution in the population with mean $\mu = mu$ and standard deviation $\sigma = sigma$, the probability of observing a result that is equal to $x$ or smaller can be calculated using `pnorm(x, mu, sigma)`. Remember that in this specific case we are taking a sample of 25 individuals, so the standard deviation of means would be normally distributed with the same mean as in the population, but the standard deviation would be $\sigma/\sqrt{n}$. 

:::


```{r ex5-solution}
# 100 - 95 - 5 / 2
pnorm(109, 115, 15 / sqrt(25))
# 0.02275013
```


## Linear regression

Cariologists are interested in the relation between Diastolic Blood Pressure (dbp in mm Hg) on the one hand and several explanatory variables on the other. They collected data on 3154 individuals and performed a linear regression analysis. The binary variable “chd” (chronic heart disease) is coded 0 (no) and 1 (yes). Age is measured in years and BMI (Body Mass Index) in kg/m2. The variable “intBMIchd” is calculated as the product of BMI and chd.

```{r Q2_lm, eval=TRUE}
knitr::include_graphics("img/Q2_lm.png")
```

6. The P-value in the last row was eliminated. Is the test in the last row significant? What null hypothesis is tested in this last row? [4]


```{r ex6-solution}
# Null hypothesis: the interaction coefficient is not signifiant
# Yes it is 
2*pt(-2.227, df = 3154 - 1)
2*pt(2.227,  df = 3154 - 1, lower.tail = FALSE)

n <- 20
tibble(x1 = rnorm(n), x2 = rnorm(n) , x3 = rnorm(n), 
       y = x1 + x2 + x3 + rnorm(n)) |> 
  lm(y ~ x1 + x2 + x3, data = _) |> 
  summary()
  
```


:::{#boxedtext}

This is a two-tailed t-test, so we want to calculate the probability of being in the tail, so for example to find the p-value associated with a two-tailed t-test with $t = 3.01, df = 100$ you run the following in R: 

```{r ex-6, echo=TRUE}
2 * pt(3.01, df = 100, lower.tail = FALSE)
```


:::


7.	What is the estimated mean dpd for a 50 years old person with a BMI of 25 and without `chd`, based on this model? [3]

```{r ex7-solution}
39.657 + 15.047 * 0  + .217 * 50 +  1.311 * 25 - .508 * 25 * 0
# 83.282
```


8.	What is the estimated mean dpd for a 50 years old person with a BMI of 30 and with `chd`, based on this model? [3]


```{r ex8-solution}

39.657 + 15.047 * 1  + .217 * 50 +  1.311 * 30 - .508 * 30 * 1
# 89.644
```

9.	Draw, as accurately as possible, the estimated relationships between BMI and dbp for 60 years old individuals with and without `chd` ~~in the separate sheet. Do not forget to put your name on this sheet.~~ [4]

:::{#boxedtext}
Here you will find a couple of diagrams, you will need to choose which one represents the correct figure. Try to reflect, what should you expect to see in the graphs? How would they look like? 
:::



```{r ex-9-img, eval=TRUE, out.width="150%"}
knitr::include_graphics("img/int_plots.png")
```


```{r ex9, echo = FALSE, eval = FALSE}

n <- 1000
chd <- rbinom(n, 1, .5)
age <- runif(n, 20, 70)
bmi <- rnorm(n, 28, 5)
dbp1 <- 39.657 + 15.047 * chd + .217 * age +  1.311 * bmi - .508 * bmi * chd + rnorm(n, 0, 5)
dbp2 <- 39.657 + 15.047 * chd + .217 * age +  1.311 * bmi + rnorm(n, 0, 5)
dbp3 <- 39.657 + 15.047 - 15.047 * chd + .217 * age +  1.311 * bmi  - .508 * bmi * chd + rnorm(n, 0, 5)
dbp4 <- 39.657 + 15.047 - 15.047 * chd + .217 * age +  1.311 * bmi + rnorm(n, 0, 5)
dbp5 <- 39.657 + 15.047 - 15.047 * chd + .217 * age +  1.311 * bmi  + .508 * bmi * chd + rnorm(n, 0, 5)
dbp6 <- 39.657 + 15.047 * chd + .217 * age +  1.311 * bmi  + .508 * bmi * chd + rnorm(n, 0, 5)

df1 <- data.frame(chd, age, bmi, dbp = dbp1) |> 
  mutate(chd = factor(chd)) 
df2 <- data.frame(chd, age, bmi, dbp = dbp2) |> 
  mutate(chd = factor(chd)) 
df3 <- data.frame(chd, age, bmi, dbp = dbp3) |> 
  mutate(chd = factor(chd)) 
df4 <- data.frame(chd, age, bmi, dbp = dbp4) |> 
  mutate(chd = factor(chd)) 
df5 <- data.frame(chd, age, bmi, dbp = dbp5) |> 
  mutate(chd = factor(chd)) 
df6 <- data.frame(chd, age, bmi, dbp = dbp6) |> 
  mutate(chd = factor(chd)) 


mdl1 <- lm(dbp ~ chd + age + bmi + bmi:chd, df1)
mdl2 <- lm(dbp ~ chd + age + bmi, df2)
mdl3 <- lm(dbp ~ chd + age + bmi + bmi:chd, df3)
mdl4 <- lm(dbp ~ chd + age + bmi, df4)
mdl5 <- lm(dbp ~ chd + age + bmi + bmi:chd, df5)
mdl6 <- lm(dbp ~ chd + age + bmi + bmi:chd, df6)


p1 <- plot_predictions(mdl1, 
     newdata = datagrid(
              chd = c(0, 1),
              age = 60, 
              bmi = seq(20, 35, by = 0.5)
              ), 
     condition = c("bmi", "chd"), draw = FALSE
) 

p2 <- plot_predictions(mdl2, 
     newdata = datagrid(
              chd = c(0, 1),
              age = 60, 
              bmi = seq(20, 35, by = 0.5)
              ), 
     condition = c("bmi", "chd"), draw = FALSE
) 
p3 <- plot_predictions(mdl3, 
     newdata = datagrid(
              chd = c(0, 1),
              age = 60, 
              bmi = seq(20, 35, by = 0.5)
              ), 
     condition = c("bmi", "chd"), draw = FALSE
) 
p4 <- plot_predictions(mdl4, 
     newdata = datagrid(
              chd = c(0, 1),
              age = 60, 
              bmi = seq(20, 35, by = 0.5)
              ), 
     condition = c("bmi", "chd"), draw = FALSE
) 
p5 <- plot_predictions(mdl5, 
     newdata = datagrid(
              chd = c(0, 1),
              age = 60, 
              bmi = seq(20, 35, by = 0.5)
              ), 
     condition = c("bmi", "chd"), draw = FALSE
) 
p6 <- plot_predictions(mdl6, 
     newdata = datagrid(
              chd = c(0, 1),
              age = 60, 
              bmi = seq(20, 35, by = 0.5)
              ), 
     condition = c("bmi", "chd"), draw = FALSE
) 


p.1 <- p1 |> 
  ggplot(aes(x = bmi, y = estimate, group = chd, color = chd)) + 
  geom_point(data = slice_sample(df1, n = 200), aes(x = bmi, y = dbp, group = chd, color = chd), alpha = .6) +
  geom_line(size = 1.5) + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(x = NULL, y = "DBP", title = "Figure 1")

 
p.2 <- p2 |> 
  ggplot( data = p2, 
            mapping = aes(x = bmi, y = estimate, group = chd, color = chd))  + 
  geom_point(data = slice_sample(df2, n = 200), aes(x = bmi, y = dbp, group = chd, color = chd), alpha = .6) +
  geom_line( size = 1.5) + 
  theme_minimal() + 
  labs(x = NULL, y = NULL, , title = "Figure 2")

p.3 <- p3 |> 
  ggplot( data = p3, 
            mapping = aes(x = bmi, y = estimate, group = chd, color = chd))  + 
  geom_point(data = slice_sample(df3, n = 200), aes(x = bmi, y = dbp, group = chd, color = chd), alpha = .6) +
  geom_line( size = 1.5) + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(x = NULL, y = "DBP", , title = "Figure 3")

p.4 <- p4 |> 
  ggplot( data = p4, 
            mapping = aes(x = bmi, y = estimate, group = chd, color = chd))  + 
  geom_point(data = slice_sample(df4, n = 200), aes(x = bmi, y = dbp, group = chd, color = chd), alpha = .6) +
  geom_line( size = 1.5) + 
  theme_minimal() + 
  labs(x = NULL, y = NULL, , title = "Figure 4")

p.5 <- p5 |> 
  ggplot( data = p5, 
            mapping = aes(x = bmi, y = estimate, group = chd, color = chd))  + 
  geom_point(data = slice_sample(df5, n = 200), aes(x = bmi, y = dbp, group = chd, color = chd), alpha = .6) +
  geom_line( size = 1.5) + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  labs(y = "DBP", title = "Figure 5")

p.6 <- p6 |> 
  ggplot( mapping = aes(x = bmi, y = estimate, group = chd, color = chd))  + 
  geom_point(data = slice_sample(df6, n = 200), aes(x = bmi, y = dbp, group = chd, color = chd), alpha = .6) +
  geom_line( size = 1.5) + 
  theme_minimal() + labs(y = NULL, title = "Figure 6")


library(patchwork)
(p.1 + p.2) / (p.3 + p.4) / (p.5 + p.6)

```


10.	The variable `Smokecat` is a categorical variable with three categories: 0 : 0 cigarettes, 1: 1 – 20 cigarettes a day, 2: more than 20 cigarettes a day. Dummy variables are created and added to the previous model to test if `Smokecat` is significant, given the other variables. Which test will be used to test the null hypothesis that `Smokecat` has no effect on `dbp`, given the other variables? [3]


:::{#boxedtext}

For this question we want a test that associates *one* p-value with all three categories. We *do not* want separate p-values for the different levels. 

:::

```{r ex10}

# type-III analysis-of-variance
# in R car::Anova(model, type = 3)

```


11.	Let’s assume `Smokecat` was not significant and not added to the model. The cardiologists want to test if `dbp` depends on BMI in a quadratic way. What will the new model look like? 

:::{#boxedtext}

Please write out the model in the following form: 

$\hat{Y} = b_0 + b_1X_{chd} + b_2X_{age} + \ldots$ 

:::


```{r ex11}
# \hat{Y} = b0 + b1*X_{chd} + b2*X_{age} + b3*X_{BMI} - b4*X_{BMI}*X_{chd} + b5*X_{BMI}^2

```


## Logistic regression


In some countries in Africa, there is a high prevalence of Microfilarial infection (0 = no, 1 = yes). A study focused on several risk factors, one of them being "area of residence".


```{r Q3_OR, eval=TRUE, out.width="120%"}
knitr::include_graphics("img/Q3_OR.png")
```


12 Calculate the Odds Ratio of having Microfilarial infection for individuals living at the savannah compared to individuals living in the forest. [4]

```{r ex12-solution}

(22 / 28) / (45 / 17)
# 0.2968254

```


13.	Also a simple logistic regression was performed. Check the OR you calculated in the previous question using the information in the table below. What is your conclusion? [4]

```{r ex13}
1 / exp(1.215)

```


```{r Q3_logit, eval=TRUE, out.width="110%"}
knitr::include_graphics("img/Q3_logit.png")
```


14.	Calculate the 95% confidence interval for the OR, based on the coefficient in the table of the simple logistic regression. [4]



:::{#boxedtext}

Try to do this twice, and see if you get the same result: 

-   First, calculate the CI of the log-odd-ratio (use the estimate plus or minus two std.errors), and then take the exponent of your result
-   Second, use R to calculate the result using the following code... 


```{r ex14, echo=TRUE}
df <- tribble(
  ~area, ~infect, ~freq, 
  0, 0, 28, 
  0, 1, ___, 
  1, 0, ___, 
  1, 1, ___
) |> uncount(freq) 

glm(infect ~ area, data = df, family = binomial) |> 
  tidy(exponentiate = TRUE, conf.int = TRUE)
  
```

:::

```{r ex14-solution}

exp(1.21 + c(-1.96, 1.96) * .403)

tribble(
  ~area, ~infect, ~freq, 
  0, 0, 28, 
  0, 1, 22, 
  1, 0, 17, 
  1, 1, 45
) |> uncount(freq) |> 
  glm(infect ~ area, data = _, family = binomial) |> 
  tidy(exponentiate = TRUE, conf.int = TRUE)


tribble(
  ~area, ~infect, ~freq, 
  0, 0, 28, 
  0, 1, 22, 
  1, 0, 17, 
  1, 1, 45
) |> uncount(freq) |> 
  glm(infect ~ area, data = _, family = binomial) |> 
  tidy( ) |> 
  mutate(ci.low = exp(estimate - 1.96*std.error), 
         ci.hi  = exp(estimate + 1.96*std.error))
  
```


See next table for a multiple logistic regression.


```{r Q3_logit_2, eval=TRUE, out.width="110%"}
knitr::include_graphics("img/Q3_logit_2.png")
```



15. What is the Wald value of Area of residence in this model? [3]

```{r}
# (1.389 / .485)^2
# 8.202024
```


:::{#boxedtext}

There is a slight difference between the test statistic we use in R and the Wald statistic, in that the test statistic we use is simply the ratio of the estimate and the standard error. The square of that ratio is the Wald statistic. In order to calculate the Wald statistic, simply take the ratio and square it.

:::

```{r ex15}

```


16.	Is sex a significant variable in this model? Justify your answer. [4]


:::{#boxedtext}

To answer the question, simply take the square root of the Wald statistic and compare it to the critical value of the appropriate t-test .

:::

17.	Which age group has the highest risk according to this model? [4]


18.	How can we test if this model fits the data? [3]
